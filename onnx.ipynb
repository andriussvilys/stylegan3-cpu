{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import re\n",
    "from typing import List, Optional, Tuple, Union\n",
    "import pickle\n",
    "import click\n",
    "import dnnlib\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import torch\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "from math import ceil\n",
    "import time\n",
    "from torch_utils import misc\n",
    "from training import networks_stylegan2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def load_networks(f, force_fp16=False):\n",
    "    if isinstance(f, str):\n",
    "        f = open(f, 'rb')\n",
    "    data = _LegacyUnpickler(f).load()\n",
    "\n",
    "    # Legacy TensorFlow pickle => convert.\n",
    "    if isinstance(data, tuple) and len(data) == 3 and all(isinstance(net, _TFNetworkStub) for net in data):\n",
    "        tf_G, tf_D, tf_Gs = data\n",
    "        G = convert_tf_generator(tf_G)\n",
    "        D = convert_tf_discriminator(tf_D)\n",
    "        G_ema = convert_tf_generator(tf_Gs)\n",
    "        data = dict(G=G, D=D, G_ema=G_ema)\n",
    "\n",
    "    # Add missing fields.\n",
    "    if 'training_set_kwargs' not in data:\n",
    "        data['training_set_kwargs'] = None\n",
    "    if 'augment_pipe' not in data:\n",
    "        data['augment_pipe'] = None\n",
    "\n",
    "    # Validate contents.\n",
    "    assert isinstance(data['G'], torch.nn.Module)\n",
    "    assert isinstance(data['D'], torch.nn.Module)\n",
    "    assert isinstance(data['G_ema'], torch.nn.Module)\n",
    "    assert isinstance(data['training_set_kwargs'], (dict, type(None)))\n",
    "    assert isinstance(data['augment_pipe'], (torch.nn.Module, type(None)))\n",
    "\n",
    "    # Force FP16.\n",
    "    if force_fp16:\n",
    "        for key in ['G', 'D', 'G_ema']:\n",
    "            old = data[key]\n",
    "            kwargs = copy.deepcopy(old.init_kwargs)\n",
    "            fp16_kwargs = kwargs.get('synthesis_kwargs', kwargs)\n",
    "            fp16_kwargs.num_fp16_res = 4\n",
    "            fp16_kwargs.conv_clamp = 256\n",
    "            if kwargs != old.init_kwargs:\n",
    "                new = type(old)(**kwargs).eval().requires_grad_(False)\n",
    "                misc.copy_params_and_buffers(old, new, require_all=True)\n",
    "                data[key] = new\n",
    "    G = data['G_ema'].requires_grad_(False).eval()\n",
    "    D = data['D'].requires_grad_(False).eval()\n",
    "    return G, D\n",
    "\n",
    "class _TFNetworkStub(dnnlib.EasyDict):\n",
    "    pass\n",
    "\n",
    "class _LegacyUnpickler(pickle.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "        if module == 'dnnlib.tflib.network' and name == 'Network':\n",
    "            return _TFNetworkStub\n",
    "        return super().find_class(module, name)\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "\n",
    "def _collect_tf_params(tf_net):\n",
    "    # pylint: disable=protected-access\n",
    "    tf_params = dict()\n",
    "    def recurse(prefix, tf_net):\n",
    "        for name, value in tf_net.variables:\n",
    "            tf_params[prefix + name] = value\n",
    "        for name, comp in tf_net.components.items():\n",
    "            recurse(prefix + name + '/', comp)\n",
    "    recurse('', tf_net)\n",
    "    return tf_params\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "\n",
    "def _populate_module_params(module, *patterns):\n",
    "    for name, tensor in misc.named_params_and_buffers(module):\n",
    "        found = False\n",
    "        value = None\n",
    "        for pattern, value_fn in zip(patterns[0::2], patterns[1::2]):\n",
    "            match = re.fullmatch(pattern, name)\n",
    "            if match:\n",
    "                found = True\n",
    "                if value_fn is not None:\n",
    "                    value = value_fn(*match.groups())\n",
    "                break\n",
    "        try:\n",
    "            assert found\n",
    "            if value is not None:\n",
    "                tensor.copy_(torch.from_numpy(np.array(value)))\n",
    "        except:\n",
    "            print(name, list(tensor.shape))\n",
    "            raise\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "\n",
    "def convert_tf_generator(tf_G):\n",
    "    if tf_G.version < 4:\n",
    "        raise ValueError('TensorFlow pickle version too low')\n",
    "\n",
    "    # Collect kwargs.\n",
    "    tf_kwargs = tf_G.static_kwargs\n",
    "    known_kwargs = set()\n",
    "    def kwarg(tf_name, default=None, none=None):\n",
    "        known_kwargs.add(tf_name)\n",
    "        val = tf_kwargs.get(tf_name, default)\n",
    "        return val if val is not None else none\n",
    "\n",
    "    # Convert kwargs.\n",
    "    network_class = networks_stylegan2.Generator\n",
    "    kwargs = dnnlib.EasyDict(\n",
    "        z_dim               = kwarg('latent_size',          512),\n",
    "        c_dim               = kwarg('label_size',           0),\n",
    "        w_dim               = kwarg('dlatent_size',         512),\n",
    "        img_resolution      = kwarg('resolution',           1024),\n",
    "        img_channels        = kwarg('num_channels',         3),\n",
    "        channel_base        = kwarg('fmap_base',            16384) * 2,\n",
    "        channel_max         = kwarg('fmap_max',             512),\n",
    "        num_fp16_res        = kwarg('num_fp16_res',         0),\n",
    "        conv_clamp          = kwarg('conv_clamp',           None),\n",
    "        architecture        = kwarg('architecture',         'skip'),\n",
    "        resample_filter     = kwarg('resample_kernel',      [1,3,3,1]),\n",
    "        use_noise           = kwarg('use_noise',            True),\n",
    "        activation          = kwarg('nonlinearity',         'lrelu'),\n",
    "        mapping_kwargs      = dnnlib.EasyDict(\n",
    "            num_layers      = kwarg('mapping_layers',       8),\n",
    "            embed_features  = kwarg('label_fmaps',          None),\n",
    "            layer_features  = kwarg('mapping_fmaps',        None),\n",
    "            activation      = kwarg('mapping_nonlinearity', 'lrelu'),\n",
    "            lr_multiplier   = kwarg('mapping_lrmul',        0.01),\n",
    "            w_avg_beta      = kwarg('w_avg_beta',           0.995,  none=1),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Check for unknown kwargs.\n",
    "    kwarg('truncation_psi')\n",
    "    kwarg('truncation_cutoff')\n",
    "    kwarg('style_mixing_prob')\n",
    "    kwarg('structure')\n",
    "    kwarg('conditioning')\n",
    "    kwarg('fused_modconv')\n",
    "    unknown_kwargs = list(set(tf_kwargs.keys()) - known_kwargs)\n",
    "    if len(unknown_kwargs) > 0:\n",
    "        raise ValueError('Unknown TensorFlow kwarg', unknown_kwargs[0])\n",
    "\n",
    "    # Collect params.\n",
    "    tf_params = _collect_tf_params(tf_G)\n",
    "    for name, value in list(tf_params.items()):\n",
    "        match = re.fullmatch(r'ToRGB_lod(\\d+)/(.*)', name)\n",
    "        if match:\n",
    "            r = kwargs.img_resolution // (2 ** int(match.group(1)))\n",
    "            tf_params[f'{r}x{r}/ToRGB/{match.group(2)}'] = value\n",
    "            kwargs.synthesis.kwargs.architecture = 'orig'\n",
    "    #for name, value in tf_params.items(): print(f'{name:<50s}{list(value.shape)}')\n",
    "\n",
    "    # Convert params.\n",
    "    G = network_class(**kwargs).eval().requires_grad_(False)\n",
    "    # pylint: disable=unnecessary-lambda\n",
    "    # pylint: disable=f-string-without-interpolation\n",
    "    _populate_module_params(G,\n",
    "        r'mapping\\.w_avg',                                  lambda:     tf_params[f'dlatent_avg'],\n",
    "        r'mapping\\.embed\\.weight',                          lambda:     tf_params[f'mapping/LabelEmbed/weight'].transpose(),\n",
    "        r'mapping\\.embed\\.bias',                            lambda:     tf_params[f'mapping/LabelEmbed/bias'],\n",
    "        r'mapping\\.fc(\\d+)\\.weight',                        lambda i:   tf_params[f'mapping/Dense{i}/weight'].transpose(),\n",
    "        r'mapping\\.fc(\\d+)\\.bias',                          lambda i:   tf_params[f'mapping/Dense{i}/bias'],\n",
    "        r'synthesis\\.b4\\.const',                            lambda:     tf_params[f'synthesis/4x4/Const/const'][0],\n",
    "        r'synthesis\\.b4\\.conv1\\.weight',                    lambda:     tf_params[f'synthesis/4x4/Conv/weight'].transpose(3, 2, 0, 1),\n",
    "        r'synthesis\\.b4\\.conv1\\.bias',                      lambda:     tf_params[f'synthesis/4x4/Conv/bias'],\n",
    "        r'synthesis\\.b4\\.conv1\\.noise_const',               lambda:     tf_params[f'synthesis/noise0'][0, 0],\n",
    "        r'synthesis\\.b4\\.conv1\\.noise_strength',            lambda:     tf_params[f'synthesis/4x4/Conv/noise_strength'],\n",
    "        r'synthesis\\.b4\\.conv1\\.affine\\.weight',            lambda:     tf_params[f'synthesis/4x4/Conv/mod_weight'].transpose(),\n",
    "        r'synthesis\\.b4\\.conv1\\.affine\\.bias',              lambda:     tf_params[f'synthesis/4x4/Conv/mod_bias'] + 1,\n",
    "        r'synthesis\\.b(\\d+)\\.conv0\\.weight',                lambda r:   tf_params[f'synthesis/{r}x{r}/Conv0_up/weight'][::-1, ::-1].transpose(3, 2, 0, 1),\n",
    "        r'synthesis\\.b(\\d+)\\.conv0\\.bias',                  lambda r:   tf_params[f'synthesis/{r}x{r}/Conv0_up/bias'],\n",
    "        r'synthesis\\.b(\\d+)\\.conv0\\.noise_const',           lambda r:   tf_params[f'synthesis/noise{int(np.log2(int(r)))*2-5}'][0, 0],\n",
    "        r'synthesis\\.b(\\d+)\\.conv0\\.noise_strength',        lambda r:   tf_params[f'synthesis/{r}x{r}/Conv0_up/noise_strength'],\n",
    "        r'synthesis\\.b(\\d+)\\.conv0\\.affine\\.weight',        lambda r:   tf_params[f'synthesis/{r}x{r}/Conv0_up/mod_weight'].transpose(),\n",
    "        r'synthesis\\.b(\\d+)\\.conv0\\.affine\\.bias',          lambda r:   tf_params[f'synthesis/{r}x{r}/Conv0_up/mod_bias'] + 1,\n",
    "        r'synthesis\\.b(\\d+)\\.conv1\\.weight',                lambda r:   tf_params[f'synthesis/{r}x{r}/Conv1/weight'].transpose(3, 2, 0, 1),\n",
    "        r'synthesis\\.b(\\d+)\\.conv1\\.bias',                  lambda r:   tf_params[f'synthesis/{r}x{r}/Conv1/bias'],\n",
    "        r'synthesis\\.b(\\d+)\\.conv1\\.noise_const',           lambda r:   tf_params[f'synthesis/noise{int(np.log2(int(r)))*2-4}'][0, 0],\n",
    "        r'synthesis\\.b(\\d+)\\.conv1\\.noise_strength',        lambda r:   tf_params[f'synthesis/{r}x{r}/Conv1/noise_strength'],\n",
    "        r'synthesis\\.b(\\d+)\\.conv1\\.affine\\.weight',        lambda r:   tf_params[f'synthesis/{r}x{r}/Conv1/mod_weight'].transpose(),\n",
    "        r'synthesis\\.b(\\d+)\\.conv1\\.affine\\.bias',          lambda r:   tf_params[f'synthesis/{r}x{r}/Conv1/mod_bias'] + 1,\n",
    "        r'synthesis\\.b(\\d+)\\.torgb\\.weight',                lambda r:   tf_params[f'synthesis/{r}x{r}/ToRGB/weight'].transpose(3, 2, 0, 1),\n",
    "        r'synthesis\\.b(\\d+)\\.torgb\\.bias',                  lambda r:   tf_params[f'synthesis/{r}x{r}/ToRGB/bias'],\n",
    "        r'synthesis\\.b(\\d+)\\.torgb\\.affine\\.weight',        lambda r:   tf_params[f'synthesis/{r}x{r}/ToRGB/mod_weight'].transpose(),\n",
    "        r'synthesis\\.b(\\d+)\\.torgb\\.affine\\.bias',          lambda r:   tf_params[f'synthesis/{r}x{r}/ToRGB/mod_bias'] + 1,\n",
    "        r'synthesis\\.b(\\d+)\\.skip\\.weight',                 lambda r:   tf_params[f'synthesis/{r}x{r}/Skip/weight'][::-1, ::-1].transpose(3, 2, 0, 1),\n",
    "        r'.*\\.resample_filter',                             None,\n",
    "        r'.*\\.act_filter',                                  None,\n",
    "    )\n",
    "    return G\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "\n",
    "def convert_tf_discriminator(tf_D):\n",
    "    if tf_D.version < 4:\n",
    "        raise ValueError('TensorFlow pickle version too low')\n",
    "\n",
    "    # Collect kwargs.\n",
    "    tf_kwargs = tf_D.static_kwargs\n",
    "    known_kwargs = set()\n",
    "    def kwarg(tf_name, default=None):\n",
    "        known_kwargs.add(tf_name)\n",
    "        return tf_kwargs.get(tf_name, default)\n",
    "\n",
    "    # Convert kwargs.\n",
    "    kwargs = dnnlib.EasyDict(\n",
    "        c_dim                   = kwarg('label_size',           0),\n",
    "        img_resolution          = kwarg('resolution',           1024),\n",
    "        img_channels            = kwarg('num_channels',         3),\n",
    "        architecture            = kwarg('architecture',         'resnet'),\n",
    "        channel_base            = kwarg('fmap_base',            16384) * 2,\n",
    "        channel_max             = kwarg('fmap_max',             512),\n",
    "        num_fp16_res            = kwarg('num_fp16_res',         0),\n",
    "        conv_clamp              = kwarg('conv_clamp',           None),\n",
    "        cmap_dim                = kwarg('mapping_fmaps',        None),\n",
    "        block_kwargs = dnnlib.EasyDict(\n",
    "            activation          = kwarg('nonlinearity',         'lrelu'),\n",
    "            resample_filter     = kwarg('resample_kernel',      [1,3,3,1]),\n",
    "            freeze_layers       = kwarg('freeze_layers',        0),\n",
    "        ),\n",
    "        mapping_kwargs = dnnlib.EasyDict(\n",
    "            num_layers          = kwarg('mapping_layers',       0),\n",
    "            embed_features      = kwarg('mapping_fmaps',        None),\n",
    "            layer_features      = kwarg('mapping_fmaps',        None),\n",
    "            activation          = kwarg('nonlinearity',         'lrelu'),\n",
    "            lr_multiplier       = kwarg('mapping_lrmul',        0.1),\n",
    "        ),\n",
    "        epilogue_kwargs = dnnlib.EasyDict(\n",
    "            mbstd_group_size    = kwarg('mbstd_group_size',     None),\n",
    "            mbstd_num_channels  = kwarg('mbstd_num_features',   1),\n",
    "            activation          = kwarg('nonlinearity',         'lrelu'),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Check for unknown kwargs.\n",
    "    kwarg('structure')\n",
    "    kwarg('conditioning')\n",
    "    unknown_kwargs = list(set(tf_kwargs.keys()) - known_kwargs)\n",
    "    if len(unknown_kwargs) > 0:\n",
    "        raise ValueError('Unknown TensorFlow kwarg', unknown_kwargs[0])\n",
    "\n",
    "    # Collect params.\n",
    "    tf_params = _collect_tf_params(tf_D)\n",
    "    for name, value in list(tf_params.items()):\n",
    "        match = re.fullmatch(r'FromRGB_lod(\\d+)/(.*)', name)\n",
    "        if match:\n",
    "            r = kwargs.img_resolution // (2 ** int(match.group(1)))\n",
    "            tf_params[f'{r}x{r}/FromRGB/{match.group(2)}'] = value\n",
    "            kwargs.architecture = 'orig'\n",
    "    #for name, value in tf_params.items(): print(f'{name:<50s}{list(value.shape)}')\n",
    "\n",
    "    # Convert params.\n",
    "    D = networks_stylegan2.Discriminator(**kwargs).eval().requires_grad_(False)\n",
    "    # pylint: disable=unnecessary-lambda\n",
    "    # pylint: disable=f-string-without-interpolation\n",
    "    _populate_module_params(D,\n",
    "        r'b(\\d+)\\.fromrgb\\.weight',     lambda r:       tf_params[f'{r}x{r}/FromRGB/weight'].transpose(3, 2, 0, 1),\n",
    "        r'b(\\d+)\\.fromrgb\\.bias',       lambda r:       tf_params[f'{r}x{r}/FromRGB/bias'],\n",
    "        r'b(\\d+)\\.conv(\\d+)\\.weight',   lambda r, i:    tf_params[f'{r}x{r}/Conv{i}{[\"\",\"_down\"][int(i)]}/weight'].transpose(3, 2, 0, 1),\n",
    "        r'b(\\d+)\\.conv(\\d+)\\.bias',     lambda r, i:    tf_params[f'{r}x{r}/Conv{i}{[\"\",\"_down\"][int(i)]}/bias'],\n",
    "        r'b(\\d+)\\.skip\\.weight',        lambda r:       tf_params[f'{r}x{r}/Skip/weight'].transpose(3, 2, 0, 1),\n",
    "        r'mapping\\.embed\\.weight',      lambda:         tf_params[f'LabelEmbed/weight'].transpose(),\n",
    "        r'mapping\\.embed\\.bias',        lambda:         tf_params[f'LabelEmbed/bias'],\n",
    "        r'mapping\\.fc(\\d+)\\.weight',    lambda i:       tf_params[f'Mapping{i}/weight'].transpose(),\n",
    "        r'mapping\\.fc(\\d+)\\.bias',      lambda i:       tf_params[f'Mapping{i}/bias'],\n",
    "        r'b4\\.conv\\.weight',            lambda:         tf_params[f'4x4/Conv/weight'].transpose(3, 2, 0, 1),\n",
    "        r'b4\\.conv\\.bias',              lambda:         tf_params[f'4x4/Conv/bias'],\n",
    "        r'b4\\.fc\\.weight',              lambda:         tf_params[f'4x4/Dense0/weight'].transpose(),\n",
    "        r'b4\\.fc\\.bias',                lambda:         tf_params[f'4x4/Dense0/bias'],\n",
    "        r'b4\\.out\\.weight',             lambda:         tf_params[f'Output/weight'].transpose(),\n",
    "        r'b4\\.out\\.bias',               lambda:         tf_params[f'Output/bias'],\n",
    "        r'.*\\.resample_filter',         None,\n",
    "    )\n",
    "    return D"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "G, D = load_networks('models/network.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%G, D = load_networks('https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl')\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnxruntime\n",
    "print(onnx.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%import onnx\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Generator(\n  (synthesis): SynthesisNetwork(\n    w_dim=512, num_ws=16,\n    img_resolution=256, img_channels=3,\n    num_layers=14, num_critical=2,\n    margin_size=10, num_fp16_res=4\n    (input): SynthesisInput(\n      w_dim=512, channels=512, size=[36, 36],\n      sampling_rate=16, bandwidth=2\n      (affine): FullyConnectedLayer(in_features=512, out_features=4, activation=linear)\n    )\n    (L0_36_512): SynthesisLayer(\n      w_dim=512, is_torgb=False,\n      is_critically_sampled=False, use_fp16=False,\n      in_sampling_rate=16, out_sampling_rate=16,\n      in_cutoff=2, out_cutoff=2,\n      in_half_width=6, out_half_width=6,\n      in_size=[36, 36], out_size=[36, 36],\n      in_channels=512, out_channels=512\n      (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n    )\n    (L1_36_512): SynthesisLayer(\n      w_dim=512, is_torgb=False,\n      is_critically_sampled=False, use_fp16=False,\n      in_sampling_rate=16, out_sampling_rate=16,\n      in_cutoff=2, out_cutoff=2.82843,\n      in_half_width=6, out_half_width=5.17157,\n      in_size=[36, 36], out_size=[36, 36],\n      in_channels=512, out_channels=512\n      (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n    )\n    (L2_36_512): SynthesisLayer(\n      w_dim=512, is_torgb=False,\n      is_critically_sampled=False, use_fp16=False,\n      in_sampling_rate=16, out_sampling_rate=16,\n      in_cutoff=2.82843, out_cutoff=4,\n      in_half_width=5.17157, out_half_width=4,\n      in_size=[36, 36], out_size=[36, 36],\n      in_channels=512, out_channels=512\n      (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n    )\n    (L3_52_512): SynthesisLayer(\n      w_dim=512, is_torgb=False,\n      is_critically_sampled=False, use_fp16=True,\n      in_sampling_rate=16, out_sampling_rate=32,\n      in_cutoff=4, out_cutoff=5.65685,\n      in_half_width=4, out_half_width=10.3431,\n      in_size=[36, 36], out_size=[52, 52],\n      in_channels=512, out_channels=512\n      (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n    )\n    (L4_52_512): SynthesisLayer(\n      w_dim=512, is_torgb=False,\n      is_critically_sampled=False, use_fp16=True,\n      in_sampling_rate=32, out_sampling_rate=32,\n      in_cutoff=5.65685, out_cutoff=8,\n      in_half_width=10.3431, out_half_width=8,\n      in_size=[52, 52], out_size=[52, 52],\n      in_channels=512, out_channels=512\n      (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n    )\n    (L5_84_512): SynthesisLayer(\n      w_dim=512, is_torgb=False,\n      is_critically_sampled=False, use_fp16=True,\n      in_sampling_rate=32, out_sampling_rate=64,\n      in_cutoff=8, out_cutoff=11.3137,\n      in_half_width=8, out_half_width=20.6863,\n      in_size=[52, 52], out_size=[84, 84],\n      in_channels=512, out_channels=512\n      (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n    )\n    (L6_84_512): SynthesisLayer(\n      w_dim=512, is_torgb=False,\n      is_critically_sampled=False, use_fp16=True,\n      in_sampling_rate=64, out_sampling_rate=64,\n      in_cutoff=11.3137, out_cutoff=16,\n      in_half_width=20.6863, out_half_width=16,\n      in_size=[84, 84], out_size=[84, 84],\n      in_channels=512, out_channels=512\n      (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n    )\n    (L7_148_512): SynthesisLayer(\n      w_dim=512, is_torgb=False,\n      is_critically_sampled=False, use_fp16=True,\n      in_sampling_rate=64, out_sampling_rate=128,\n      in_cutoff=16, out_cutoff=22.6274,\n      in_half_width=16, out_half_width=41.3726,\n      in_size=[84, 84], out_size=[148, 148],\n      in_channels=512, out_channels=512\n      (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n    )\n    (L8_148_512): SynthesisLayer(\n      w_dim=512, is_torgb=False,\n      is_critically_sampled=False, use_fp16=True,\n      in_sampling_rate=128, out_sampling_rate=128,\n      in_cutoff=22.6274, out_cutoff=32,\n      in_half_width=41.3726, out_half_width=32,\n      in_size=[148, 148], out_size=[148, 148],\n      in_channels=512, out_channels=512\n      (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n    )\n    (L9_148_362): SynthesisLayer(\n      w_dim=512, is_torgb=False,\n      is_critically_sampled=False, use_fp16=True,\n      in_sampling_rate=128, out_sampling_rate=128,\n      in_cutoff=32, out_cutoff=45.2548,\n      in_half_width=32, out_half_width=18.7452,\n      in_size=[148, 148], out_size=[148, 148],\n      in_channels=512, out_channels=362\n      (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n    )\n    (L10_276_256): SynthesisLayer(\n      w_dim=512, is_torgb=False,\n      is_critically_sampled=False, use_fp16=True,\n      in_sampling_rate=128, out_sampling_rate=256,\n      in_cutoff=45.2548, out_cutoff=64,\n      in_half_width=18.7452, out_half_width=64,\n      in_size=[148, 148], out_size=[276, 276],\n      in_channels=362, out_channels=256\n      (affine): FullyConnectedLayer(in_features=512, out_features=362, activation=linear)\n    )\n    (L11_276_181): SynthesisLayer(\n      w_dim=512, is_torgb=False,\n      is_critically_sampled=False, use_fp16=True,\n      in_sampling_rate=256, out_sampling_rate=256,\n      in_cutoff=64, out_cutoff=90.5097,\n      in_half_width=64, out_half_width=37.4903,\n      in_size=[276, 276], out_size=[276, 276],\n      in_channels=256, out_channels=181\n      (affine): FullyConnectedLayer(in_features=512, out_features=256, activation=linear)\n    )\n    (L12_276_128): SynthesisLayer(\n      w_dim=512, is_torgb=False,\n      is_critically_sampled=True, use_fp16=True,\n      in_sampling_rate=256, out_sampling_rate=256,\n      in_cutoff=90.5097, out_cutoff=128,\n      in_half_width=37.4903, out_half_width=29.5865,\n      in_size=[276, 276], out_size=[276, 276],\n      in_channels=181, out_channels=128\n      (affine): FullyConnectedLayer(in_features=512, out_features=181, activation=linear)\n    )\n    (L13_256_128): SynthesisLayer(\n      w_dim=512, is_torgb=False,\n      is_critically_sampled=True, use_fp16=True,\n      in_sampling_rate=256, out_sampling_rate=256,\n      in_cutoff=128, out_cutoff=128,\n      in_half_width=29.5865, out_half_width=29.5865,\n      in_size=[276, 276], out_size=[256, 256],\n      in_channels=128, out_channels=128\n      (affine): FullyConnectedLayer(in_features=512, out_features=128, activation=linear)\n    )\n    (L14_256_3): SynthesisLayer(\n      w_dim=512, is_torgb=True,\n      is_critically_sampled=True, use_fp16=True,\n      in_sampling_rate=256, out_sampling_rate=256,\n      in_cutoff=128, out_cutoff=128,\n      in_half_width=29.5865, out_half_width=29.5865,\n      in_size=[256, 256], out_size=[256, 256],\n      in_channels=128, out_channels=3\n      (affine): FullyConnectedLayer(in_features=512, out_features=128, activation=linear)\n    )\n  )\n  (mapping): MappingNetwork(\n    z_dim=512, c_dim=0, w_dim=512, num_ws=16\n    (fc0): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n    (fc1): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n  )\n)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "dummy_z = torch.rand(1, G.z_dim, generator=torch.Generator().manual_seed(0), device='cpu')\n",
    "dummy_label = torch.zeros([1, G.c_dim])\n",
    "truncation_psi = torch.tensor(1)\n",
    "noise_mode = 'const'\n",
    "dummy_input = (dummy_z, dummy_label, truncation_psi, noise_mode)\n",
    "input_names = [ \"input.z\", \"input.label\", \"input.truncation\", \"input.noise_mode\" ]\n",
    "output_names = [ \"output.image\" ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%dummy_input = torch.randn(1, 512, device='cuda')\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "img = G(*dummy_input)\n",
    "img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
    "img = PIL.Image.fromarray(img[0].cpu().numpy(), 'RGB')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%sess = onnxruntime.InferenceSession(\"models/network.onnx\")result\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:159: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Exporting the operator affine_grid_generator to ONNX opset version 13 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [10], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43monnx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexport\u001B[49m\u001B[43m(\u001B[49m\u001B[43mG\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdummy_input\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodels/network.onnx\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_names\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m                \u001B[49m\u001B[43mopset_version\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m13\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\stylegan3-cpu\\lib\\site-packages\\torch\\onnx\\__init__.py:271\u001B[0m, in \u001B[0;36mexport\u001B[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_raw_ir, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;124;03mExport a model into ONNX format.  This exporter runs your model\u001B[39;00m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;124;03monce in order to get a trace of its execution to be exported;\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    267\u001B[0m \u001B[38;5;124;03m        than ONNX.\u001B[39;00m\n\u001B[0;32m    268\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    270\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01monnx\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m utils\n\u001B[1;32m--> 271\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexport\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexport_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    272\u001B[0m \u001B[43m                    \u001B[49m\u001B[43minput_names\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_names\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maten\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexport_raw_ir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    273\u001B[0m \u001B[43m                    \u001B[49m\u001B[43moperator_export_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopset_version\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_retain_param_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    274\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mdo_constant_folding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexample_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    275\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mstrip_doc_string\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdynamic_axes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeep_initializers_as_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    276\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mcustom_opsets\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menable_onnx_checker\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_external_data_format\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\stylegan3-cpu\\lib\\site-packages\\torch\\onnx\\utils.py:88\u001B[0m, in \u001B[0;36mexport\u001B[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_raw_ir, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\u001B[0m\n\u001B[0;32m     86\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     87\u001B[0m         operator_export_type \u001B[38;5;241m=\u001B[39m OperatorExportTypes\u001B[38;5;241m.\u001B[39mONNX\n\u001B[1;32m---> 88\u001B[0m \u001B[43m_export\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexport_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_names\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     89\u001B[0m \u001B[43m        \u001B[49m\u001B[43moperator_export_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moperator_export_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopset_version\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mopset_version\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     90\u001B[0m \u001B[43m        \u001B[49m\u001B[43m_retain_param_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_retain_param_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdo_constant_folding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdo_constant_folding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     91\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexample_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexample_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstrip_doc_string\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstrip_doc_string\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     92\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdynamic_axes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdynamic_axes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeep_initializers_as_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_initializers_as_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     93\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcustom_opsets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_opsets\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menable_onnx_checker\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43menable_onnx_checker\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     94\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_external_data_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_external_data_format\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\stylegan3-cpu\\lib\\site-packages\\torch\\onnx\\utils.py:691\u001B[0m, in \u001B[0;36m_export\u001B[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, example_outputs, opset_version, _retain_param_name, do_constant_folding, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, enable_onnx_checker, use_external_data_format, onnx_shape_inference, use_new_jit_passes)\u001B[0m\n\u001B[0;32m    687\u001B[0m     dynamic_axes \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    688\u001B[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001B[0;32m    690\u001B[0m graph, params_dict, torch_out \u001B[38;5;241m=\u001B[39m \\\n\u001B[1;32m--> 691\u001B[0m     \u001B[43m_model_to_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    692\u001B[0m \u001B[43m                    \u001B[49m\u001B[43moutput_names\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moperator_export_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    693\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mexample_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_retain_param_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    694\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mval_do_constant_folding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    695\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mfixed_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfixed_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    696\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    697\u001B[0m \u001B[43m                    \u001B[49m\u001B[43muse_new_jit_passes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_new_jit_passes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    698\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mdynamic_axes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdynamic_axes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    700\u001B[0m \u001B[38;5;66;03m# TODO: Don't allocate a in-memory string for the protobuf\u001B[39;00m\n\u001B[0;32m    701\u001B[0m defer_weight_export \u001B[38;5;241m=\u001B[39m export_type \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ExportTypes\u001B[38;5;241m.\u001B[39mPROTOBUF_FILE\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\stylegan3-cpu\\lib\\site-packages\\torch\\onnx\\utils.py:460\u001B[0m, in \u001B[0;36m_model_to_graph\u001B[1;34m(model, args, verbose, input_names, output_names, operator_export_type, example_outputs, _retain_param_name, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, use_new_jit_passes, dynamic_axes)\u001B[0m\n\u001B[0;32m    454\u001B[0m graph, params, torch_out, module \u001B[38;5;241m=\u001B[39m _create_jit_graph(model, args,\n\u001B[0;32m    455\u001B[0m                                                      _retain_param_name,\n\u001B[0;32m    456\u001B[0m                                                      use_new_jit_passes)\n\u001B[0;32m    458\u001B[0m params_dict \u001B[38;5;241m=\u001B[39m _get_named_param_dict(graph, params)\n\u001B[1;32m--> 460\u001B[0m graph \u001B[38;5;241m=\u001B[39m \u001B[43m_optimize_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgraph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moperator_export_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    461\u001B[0m \u001B[43m                        \u001B[49m\u001B[43m_disable_torch_constant_prop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_disable_torch_constant_prop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    462\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mfixed_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfixed_batch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    463\u001B[0m \u001B[43m                        \u001B[49m\u001B[43muse_new_jit_passes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_new_jit_passes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    464\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mdynamic_axes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdynamic_axes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    465\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mmodule\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodule\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    466\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01monnx\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msymbolic_helper\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _onnx_shape_inference\n\u001B[0;32m    467\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(model, torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mScriptModule) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(model, torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mScriptFunction):\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\stylegan3-cpu\\lib\\site-packages\\torch\\onnx\\utils.py:206\u001B[0m, in \u001B[0;36m_optimize_graph\u001B[1;34m(graph, operator_export_type, _disable_torch_constant_prop, fixed_batch_size, params_dict, use_new_jit_passes, dynamic_axes, input_names, module)\u001B[0m\n\u001B[0;32m    204\u001B[0m     dynamic_axes \u001B[38;5;241m=\u001B[39m {} \u001B[38;5;28;01mif\u001B[39;00m dynamic_axes \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m dynamic_axes\n\u001B[0;32m    205\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_jit_pass_onnx_set_dynamic_input_shape(graph, dynamic_axes, input_names)\n\u001B[1;32m--> 206\u001B[0m graph \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jit_pass_onnx\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgraph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moperator_export_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    207\u001B[0m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_jit_pass_lint(graph)\n\u001B[0;32m    209\u001B[0m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_jit_pass_onnx_scalar_type_analysis(graph)\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\stylegan3-cpu\\lib\\site-packages\\torch\\onnx\\__init__.py:309\u001B[0m, in \u001B[0;36m_run_symbolic_function\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    307\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_symbolic_function\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    308\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01monnx\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m utils\n\u001B[1;32m--> 309\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_symbolic_function\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\stylegan3-cpu\\lib\\site-packages\\torch\\onnx\\utils.py:990\u001B[0m, in \u001B[0;36m_run_symbolic_function\u001B[1;34m(g, n, inputs, env, operator_export_type)\u001B[0m\n\u001B[0;32m    987\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    988\u001B[0m     \u001B[38;5;66;03m# Export it regularly\u001B[39;00m\n\u001B[0;32m    989\u001B[0m     domain \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m--> 990\u001B[0m     symbolic_fn \u001B[38;5;241m=\u001B[39m \u001B[43m_find_symbolic_in_registry\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdomain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopset_version\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moperator_export_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    991\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m symbolic_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    992\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\stylegan3-cpu\\lib\\site-packages\\torch\\onnx\\utils.py:947\u001B[0m, in \u001B[0;36m_find_symbolic_in_registry\u001B[1;34m(domain, op_name, opset_version, operator_export_type)\u001B[0m\n\u001B[0;32m    944\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m operator_export_type \u001B[38;5;241m==\u001B[39m OperatorExportTypes\u001B[38;5;241m.\u001B[39mONNX_FALLTHROUGH:\n\u001B[0;32m    945\u001B[0m         \u001B[38;5;66;03m# Use the original node directly\u001B[39;00m\n\u001B[0;32m    946\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 947\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msym_registry\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_registered_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdomain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopset_version\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\stylegan3-cpu\\lib\\site-packages\\torch\\onnx\\symbolic_registry.py:112\u001B[0m, in \u001B[0;36mget_registered_op\u001B[1;34m(opname, domain, version)\u001B[0m\n\u001B[0;32m    110\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    111\u001B[0m         msg \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease feel free to request support or submit a pull request on PyTorch GitHub.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 112\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(msg)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _registry[(domain, version)][opname]\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Exporting the operator affine_grid_generator to ONNX opset version 13 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub."
     ]
    }
   ],
   "source": [
    "torch.onnx.export(G, dummy_input, \"models/network.onnx\", verbose=True, input_names=input_names, output_names=output_names,\n",
    "                opset_version=13)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%input_names = [ \"input.1\", \"input.2\", \"input.3\", \"input.4\" ]\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(\"models/network.onnx\")\n",
    "onnx.checker.check_model(onnx_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}